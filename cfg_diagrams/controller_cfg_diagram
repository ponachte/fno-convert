digraph clustercontroller {
	graph [label=controller]
	3 [label="#3
data = process_data(conf, data)
if data is not None:
"]
	4 [label="#4
if len(data) > conf['min_duration_s'] * conf['frequency']:
"]
	7 [label="#7
print('Received enough data to proceed with making predictions')
data.set_index('Timestamp', inplace=True)
chunks = chunk_data(data=data, fs_dict={name: conf['frequency'] for name in
    data.columns}, min_chunk_dur='15s')
"]
	10 [label="#10
for chunk in chunks:
"]
	11 [label="#11
chunk_df = reduce(lambda x, y: pd.merge(x, y, on='Timestamp', how='inner'),
    chunk)
print('start time of chunk is ', str(chunk_df.index[0]))
print('end time of chunk is ', str(chunk_df.index[-1]))
if len(chunk_df) >= conf['win_size_s'] * conf['frequency']:
"]
	13 [label="#13
for col in ['ACC_x', 'ACC_y', 'ACC_z']:
"]
	15 [label="#15
chunk_df[col] = pd.to_numeric(chunk_df[col], errors='coerce')
chunk_df.dropna(subset=[col], inplace=True)
chunk_df[col] = chunk_df[col].round().astype(float)
"]
	15 -> 13 [label=""]
	13 -> 15 [label="['ACC_x', 'ACC_y', 'ACC_z']"]
	16 [label="#16
on_table_df = is_on_table(chunk_df.copy())
counts = np.bincount(np.array(on_table_df.is_on_table.values, dtype='int64'))
on_table = np.argmax(counts)
if on_table == 0:
"]
	17 [label="#17
chunk_df.loc[:, ['ACC_x', 'ACC_y', 'ACC_z']] = chunk_df.loc[:, ['ACC_x',
    'ACC_y', 'ACC_z']] / 9.81
x_acc, y_acc, z_acc, timestamps = rolling_acc(chunk_df.copy(), conf[
    'win_size_s'], conf['frequency'], conf['overlap'])
x_acc_df = pd.DataFrame(x_acc, columns=[('acc_x_' + str(x)) for x in range(
    len(x_acc[0]))])
del x_acc
y_acc_df = pd.DataFrame(y_acc, columns=[('acc_y_' + str(x)) for x in range(
    len(y_acc[0]))])
del y_acc
z_acc_df = pd.DataFrame(z_acc, columns=[('acc_z_' + str(x)) for x in range(
    len(z_acc[0]))])
del z_acc
model_input = np.stack([x_acc_df, y_acc_df, z_acc_df], axis=2)
del x_acc_df, y_acc_df, z_acc_df
predictions = model.predict(model_input)
majority_prediction = np.argmax(np.bincount(np.argmax(predictions, axis=1)))
final_prediction = act_dict_inverse[majority_prediction]
"]
	18 [label="#18
chunk_df.reset_index(inplace=True, drop=False)
start_ms = chunk_df.iloc[0].Timestamp.value // 10 ** 6
end_ms = chunk_df.iloc[-1].Timestamp.value // 10 ** 6
print('Predicted ', final_prediction)
print('Start time %s, End time %s' % (str(pd.to_datetime(start_ms, unit=
    'ms')), str(pd.to_datetime(end_ms, unit='ms'))))
"]
	18 -> 10 [label=""]
	17 -> 18 [label=""]
	16 -> 17 [label="on_table == 0"]
	19 [label="#19
final_prediction = 'OnTable'
"]
	19 -> 18 [label=""]
	16 -> 19 [label="(on_table != 0)"]
	13 -> 16 [label=""]
	11 -> 13 [label="len(chunk_df) >= conf['win_size_s'] * conf['frequency']"]
	11 -> 10 [label="(len(chunk_df) < conf['win_size_s'] * conf['frequency'])"]
	10 -> 11 [label=chunks]
	7 -> 10 [label=""]
	4 -> 7 [label="len(data) > conf['min_duration_s'] * conf['frequency']"]
	9 [label="#9
print('Did not receive enough data to proceed with making predictions')
"]
	4 -> 9 [label="(len(data) <= conf['min_duration_s'] * conf['frequency'])"]
	3 -> 4 [label="data is not None"]
	6 [label="#6
print('No data returned')
"]
	3 -> 6 [label="(data is None)"]
}
