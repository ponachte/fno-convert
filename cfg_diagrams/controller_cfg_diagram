digraph clustercontroller {
	graph [label=controller]
	3 [label="#3
data = process_data(conf, data)
if data is not None:
"]
	4 [label="#4
if len(data) > conf['min_duration_s'] * conf['frequency']:
"]
	7 [label="#7
print('Received enough data to proceed with making predictions')
data.set_index('Timestamp', inplace=True)
fs_dict = {}
"]
	10 [label="#10
for name in data.columns:
"]
	11 [label="#11
fs_dict[name] = conf['frequency']
"]
	11 -> 10 [label=""]
	10 -> 11 [label="data.columns"]
	12 [label="#12
chunks = chunk_data(data=data, fs_dict=fs_dict, min_chunk_dur='15s')
"]
	13 [label="#13
for chunk in chunks:
"]
	14 [label="#14
chunk_df = reduce(lambda x, y: pd.merge(x, y, on='Timestamp', how='inner'),
    chunk)
print('start time of chunk is ', str(chunk_df.index[0]))
print('end time of chunk is ', str(chunk_df.index[-1]))
if len(chunk_df) >= conf['win_size_s'] * conf['frequency']:
"]
	16 [label="#16
for col in ['ACC_x', 'ACC_y', 'ACC_z']:
"]
	18 [label="#18
chunk_df[col] = pd.to_numeric(chunk_df[col], errors='coerce')
chunk_df.dropna(subset=[col], inplace=True)
chunk_df[col] = chunk_df[col].round().astype(float)
"]
	18 -> 16 [label=""]
	16 -> 18 [label="['ACC_x', 'ACC_y', 'ACC_z']"]
	19 [label="#19
on_table_df = is_on_table(chunk_df.copy())
counts = np.bincount(np.array(on_table_df.is_on_table.values, dtype='int64'))
on_table = np.argmax(counts)
if on_table == 0:
"]
	20 [label="#20
chunk_df.loc[:, ['ACC_x', 'ACC_y', 'ACC_z']] = chunk_df.loc[:, ['ACC_x',
    'ACC_y', 'ACC_z']] / 9.81
x_acc, y_acc, z_acc, timestamps = rolling_acc(chunk_df.copy(), conf[
    'win_size_s'], conf['frequency'], conf['overlap'])
x_acc_df = pd.DataFrame(x_acc, columns=[('acc_x_' + str(x)) for x in range(
    len(x_acc[0]))])
y_acc_df = pd.DataFrame(y_acc, columns=[('acc_y_' + str(x)) for x in range(
    len(y_acc[0]))])
z_acc_df = pd.DataFrame(z_acc, columns=[('acc_z_' + str(x)) for x in range(
    len(z_acc[0]))])
x_acc = y_acc = z_acc = None
model_input = np.stack([x_acc_df, y_acc_df, z_acc_df], axis=2)
del x_acc_df, y_acc_df, z_acc_df
predictions = model.predict(model_input)
majority_prediction = np.argmax(np.bincount(np.argmax(predictions, axis=1)))
final_prediction = act_dict_inverse[majority_prediction]
"]
	21 [label="#21
chunk_df.reset_index(inplace=True, drop=False)
start_ms = chunk_df.iloc[0].Timestamp.value // 10 ** 6
end_ms = chunk_df.iloc[-1].Timestamp.value // 10 ** 6
print('Predicted ', final_prediction)
print('Start time %s, End time %s' % (str(pd.to_datetime(start_ms, unit=
    'ms')), str(pd.to_datetime(end_ms, unit='ms'))))
"]
	21 -> 13 [label=""]
	20 -> 21 [label=""]
	19 -> 20 [label="on_table == 0"]
	22 [label="#22
final_prediction = 'OnTable'
"]
	22 -> 21 [label=""]
	19 -> 22 [label="(on_table != 0)"]
	16 -> 19 [label=""]
	14 -> 16 [label="len(chunk_df) >= conf['win_size_s'] * conf['frequency']"]
	14 -> 13 [label="(len(chunk_df) < conf['win_size_s'] * conf['frequency'])"]
	13 -> 14 [label=chunks]
	12 -> 13 [label=""]
	10 -> 12 [label=""]
	7 -> 10 [label=""]
	4 -> 7 [label="len(data) > conf['min_duration_s'] * conf['frequency']"]
	9 [label="#9
print('Did not receive enough data to proceed with making predictions')
"]
	4 -> 9 [label="(len(data) <= conf['min_duration_s'] * conf['frequency'])"]
	3 -> 4 [label="data is not None"]
	6 [label="#6
print('No data returned')
"]
	3 -> 6 [label="(data is None)"]
}
